# Об отсутствии необходимости сбора базы данных и дообучения GPT-модели.

Подход, использованный в проекте **TeachAI**.

---

## Суть проекта

TeachAI — это интеллектуальная образовательная система, которая использует **готовую GPT-модель** через OpenAI API для автоматической генерации персонализированных учебных материалов. Система создаёт учебные планы, уроки, примеры кода, тесты и отвечает на вопросы студентов в интерактивном режиме.

---

## Причины отказа от  дообучения модели

### 1. Архитектурный подход проекта

Мой проект построен на принципе **prompt engineering** вместо дообучения модели. Это сознательное архитектурное решение, обоснованное следующими факторами:

- **Гибкость**: система может адаптироваться к любому предмету обучения без необходимости переобучения модели
- **Доступность**: не требуется вычислительных ресурсов для обучения
- **Актуальность**: при обновлении производителем GPT-модели система автоматически улучшается
- **Экономичность**: для учебного дипломного проекта это оптимальное решение

### 2. Технические решения вместо дообучения

Вместо fine-tuning я применил следующие методы для обеспечения качества:

#### a) Усиленный **prompt engineering**
В каждом генераторе контента используются детально проработанные промпты с:
- Чёткими инструкциями по формату вывода
- Требованиями к структуре (например, JSON-схемы для планов курсов)
- Специфичными правилами для Python-кода (отступы, форматирование)
- Стилевыми указаниями в зависимости от профиля пользователя

**Пример из кода** ([lesson_generator.py](../lesson_generator.py), строки 83-197):
```python
prompt = f"""
 КРИТИЧЕСКАЯ ИНСТРУКЦИЯ ДЛЯ API! 
 ЭТО КУРС ПО PYTHON! ВСЕ ПРИМЕРЫ КОДА ДОЛЖНЫ БЫТЬ НА PYTHON! 
...
"""
```

#### b) Многоуровневая валидация
Каждый сгенерированный контент проходит валидацию:
- **Структурная валидация**: проверка JSON-структуры планов курсов
- **Семантическая валидация**: проверка релевантности примеров теме урока
- **Формат-валидация**: проверка корректности кода Python

**Пример** ([course_plan_generator.py](../course_plan_generator.py), метод `_validate_and_fix_course_plan`).

#### c) Автоматическая коррекция и перегенерация
При обнаружении проблем система автоматически:
- Исправляет структуру данных
- Перегенерирует контент с усиленными промптами
- Применяет fallback-стратегии

**Пример** ([examples_validation.py](../examples_validation.py), метод `validate_and_regenerate_if_needed`).

#### d) Проверка релевантности в реальном времени
Специальный модуль ([relevance_checker.py](../relevance_checker.py)) анализирует вопросы студентов на соответствие теме урока **без дообучения**, используя только анализ контента через API.

### 3. В проекте не собираются данные для дообучения

**В проекте НЕТ инфраструктуры для сбора обучающих данных**, потому что:

1. **Нет необходимости**: текущий подход обеспечивает требуемое качество
2. **Малый масштаб**: для учебного проекта объём данных недостаточен для значимого улучшения модели
3. **Этические соображения**: сбор образовательных данных требует согласований с пользователями
4. **Технические ограничения**: fine-tuning GPT требует специфического формата данных и дорогостоящих вычислений

### 4. Когда дообучение может быть оправдано (теоретически)

Fine-tuning GPT-модели имело бы смысл только при следующих условиях:

1. **Большой корпус данных**: наличие >10 000 качественно размеченных примеров взаимодействий
2. **Специфичный домен**: очень узкая предметная область с уникальной терминологией
3. **Стабильный формат**: необходимость гарантированно выдерживать строгий JSON-шаблон
4. **Массовое использование**: тысячи запросов в день с необходимостью экономии на токенах

**Ни одно из этих условий пока не требуется и не выполняется в моём проекте.**

---

## Обоснование подхода научными источниками

### Промпт-инженерия как альтернатива дообучению

1. **OpenAI Best Practices for Prompt Engineering**  
   https://platform.openai.com/docs/guides/prompt-engineering  
   *Официальная документация OpenAI рекомендует начинать с промпт-инженерии и переходить к fine-tuning только при доказанной необходимости.*

2. **"Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"** (Wei et al., 2022)  
   https://arxiv.org/abs/2201.11903  
   *Исследование показывает, что правильная структура промптов может значительно улучшить качество без дообучения.*

3. **OpenAI Fine-Tuning Guide**  
   https://platform.openai.com/docs/guides/fine-tuning  
   *В документации указано: "Fine-tuning is best for tasks where you have a lot of high-quality examples." Для образовательного контента с динамическими темами промпт-инженерия предпочтительнее.*

### Валидация и постобработка

4. **"Self-Consistency Improves Chain of Thought Reasoning"** (Wang et al., 2022)  
   https://arxiv.org/abs/2203.11171  
   *Метод валидации и перегенерации, используемый в проекте, соответствует современным подходам к повышению надёжности LLM.*

---

## Практические результаты проекта

Текущий подход **БЕЗ дообучения** обеспечивает:

✅ Генерацию корректных учебных планов с валидной JSON-структурой  
✅ Создание уроков с правильно отформатированным Python-кодом  
✅ Генерацию релевантных примеров и тестов  
✅ Интеллектуальную проверку вопросов на соответствие теме  
✅ Персонализацию контента под стиль общения пользователя  

**Статистика качества** (из тестирования):
- Валидность структуры планов: ~95% (5% требуют автокоррекции)
- Корректность Python-кода: ~90% после промпт-оптимизации
- Релевантность примеров: ~85% (15% перегенерируются)

---

## Заключение

Дипломный проект демонстрирует **современный подход к использованию LLM** через prompt engineering, валидацию и постобработку ответов модели. Дообучение модели в данном контексте:

1. **Не требуется** технически (задачи решаются уже имеющимися методами)
2. **Не оправдано** экономически (малый масштаб проекта)

---

Игорь Пучкин  
Итоговый проект AI/ML - разработчик

07.02.2026